# ğŸŒŸ Elevate AI & ML Internship â€“ Task 6

## ğŸ§  K-Nearest Neighbors (KNN) Classification

This task focuses on implementing the KNN algorithm using the Iris dataset. KNN is a simple yet powerful instance-based learning method, where predictions are made based on the majority class among the K-nearest neighbors.

---

### ğŸ“‚ Dataset:
- **Name:** Iris Dataset
- **Source:** scikit-learn built-in dataset
- **Classes:** Setosa, Versicolor, Virginica
- **Features:** Sepal length, Sepal width, Petal length, Petal width

---

### ğŸ”§ Tools Used:
- Python
- Google Colab
- scikit-learn
- pandas
- matplotlib
- seaborn

---

### ğŸ” What I Did:

1. Loaded the Iris dataset and converted it into a pandas DataFrame.
2. Normalized the feature values using `StandardScaler` to improve distance calculations.
3. Split the dataset into training and testing sets.
4. Implemented `KNeighborsClassifier` with K=3.
5. Evaluated the model using:
   - Accuracy score
   - Confusion Matrix (with heatmap)
6. Experimented with different values of K (1â€“10) and plotted their accuracies.
7. Visualized decision boundaries using the first two features.

---

### ğŸ“ˆ Accuracy Achieved:
> **Accuracy with K=3:** *1.0*

---

### ğŸ“Œ Learnings:
- How KNN works based on distance and neighborhood voting.
- Why normalization is essential in distance-based algorithms.
- How to tune the `K` value using validation.
- How to visualize decision boundaries in 2D.

---

### ğŸ‘¨â€ğŸ’» Author:
**NROUPSINH KALPESHSINGH GOHIL**  
Elevate AI & ML Internship  
Task 6 â€“ KNN Classification
